# Introduction {#introduction}

Insurance rating algorithms are becoming more complex as companies replatform to new technologies, find more ways to segment costs, and identify and adapt to new data sources. It is becoming increasingly difficult for actuaries and other insurance professionals to obtain accurate onleveled premium at the exposure level.  This may happen for several reasons:

(1) The company did not invest in re-rating technologies, capturing critical information, or detailed exposure data.  
(2) The demands on the actuary to provide policy or exposure level data is increasing.
(3) Rating systems are on outdated IT platforms, many from the innovations in the 1970.  These systems work well but are not well understood in many cases.
(4) Business requirements were not robust enough or missed details whenb developing rating systems.

There ia a need for a faster more accurate approach to approximate onlevel premiums.  Traditional approaches are time-comsuming and are often left with problems that never get resolved.  An approach that is agnostic to 

(1) Bring policy premiums to current rate level for actuarial and other financial analysis.
(2) Verifying policy rating systems are compliant with intended rates.
(3) Data scienstists and research professionals need onleveled premiums for some models and the traditional techniques (such as pallelogram method) do not onelevel premium accurately enough at a lower grain.  Incorrect premiums can add skew and mis-align results. (Chuck, can you show this somehow?)
(4) Product/portfolio managers want to view there book of business at a finer 
(5) A rating system is often used to simulate.

Over the years a company may have licensed many writing companies each with their "code" or rating algorithm across multiple systems with varying versions of code. This makes it difficult to rate policies in batch. If IT and actuaries do not have the ability to do this then assumptions to be made and particular details need to be addressed directly.

## Extension of Exposures 

Extension of exposures (EoE) is the method in which every policy is rated according to some "rate book" version which typically includes these components:

(1) Set of rate tables.
(2) Rating steps / Rating formula / Rating Algorithm.
(3) Policy attribute data / rating data.

This method restates the historical premium to the amount that would be charged under the rates set forth by the rate book.  In theory, thois could be at any rate level as prescribed by the rate book version.  However, this is often not the case.  These system

However, this implies a dataset does exist see \@ref(theory).

Extension of exposures has the advantage of being the most accurate current rate level method, assuming the actuary has access to the detailed data required. 

In the past, extension of exposures was practically impossible due to the significant number of calculations required to rerate each policy. Given the
tremendous increase in computing power, the only remaining hurdle is associated with gathering the required data. To adjust premium to the current rate level using the extension of exposures technique, the practitioner needs to know the applicable rating characteristics for every policy in the historical period.
Often companies do not have that information readily available.

Returning to the example, assume the actuary wishes to adjust the historical premium for Policy
Year 2011 to the current rate level. Assume one such policy was effective on March 1, 2011 and had 10
class Y exposures. The actual premium charged for the policy was based on the rates effective on
January 1, 2011, and was $7,370 (= 10 x $1,045 x 0.60 + $1,100). To put the premium on-level,
substitute the current base rate, class factor, and policy fee in the calculations; this results in an on-level
premium of $8,405 (= 10 x $1,045 x 0.70 + $1,090). This same calculation is performed for every policy
written in 2011 and then aggregated across all policies.
If a group of policies has the exact same rating characteristics, they can be grouped for the purposes of the
extension of exposures technique. This type of grouping is—practically speaking—only relevant in lines
with relatively simple rating algorithms and very few rating variables.
In some commercial lines products, underwriters can apply subjective debits and credits to manual
premium. This complicates the use of the extension of exposures technique since it may be difficult to
determine what debits and credits would be applied under today’s schedule rating guidelines. The actuary
may consider measuring how credit and debit practices have changed by reviewing distributions of debits
and credits over recent years. 

## Why neural nets?

Neural nets have been said to compute any function within certain approximation (http://neuralnetworksanddeeplearning.com/chap4.html).  There is a tradeoff between accuracy and computational time; the deeper complexity of the neural net leads to more accuracy but longer learning time.  These approximations are good enough for actuaries (see later section). 

Premiums are a function of $x$ features, a closed system with many but only finit possible outcomes. Outcomes are not evenly distributed which is often referred to as mix of business.

Unstructured data can be used.

The traditional approach versus the NN approach.  The traditional approach consists of tracking down the exact value of every feature and matching the levels exactly to the.  When a change is made to the algorithm, a rating variable, or table structure, this must be manually programmed again by actuaries.

The NN approach is to approximate the function.  We want to get within a $1.  The downside, which we will explore later, is the .  The traditional approach must happen in the first place in order for premium data to be generated and collected. Neural nets rely on a sample of premium data.  By its definition if the premium data has errors the neural net would target the "incorrect premiums", and fit to a system that was not intended by the traditional approach.

### Hypothesis and Theory {#theory}

#### Theory on the data.  

Logic: if policy premium is generated.

Show diagram of data in / data out.  

Data needs to be on one row for each exposure - that means we can test out the flat fee versus not flat fee.

#### Theory on the rating algorithm

Neural nets should